from bin.helper_function import *
from bin.multiAlignGenomeLTRs import RunAndParseClustal
from bin.pathfinder import ProjectStructure
from bin.messager import *
from bin.LTRharvest_loop import LTRharvestRun
from bin.InsertionTimeEstimation import LTR_InsertionTimeCalculator
import argparse
from Bio import SeqIO
import os
from bin import Clustering_LTRs
from bin.screenSelectedLTRbyBLASTgenome import checkLTR_bygBLAST
from bin.selectCluster_for_iRAP import *

class iRAPer():
    def __init__(self, args):
        print("The iRAPer pipeline has been started >>> ")
        self.args = args
        self.genome = args.genome
        self.skip = args.skip
        self.trna = args.trna
        self.profiles = args.profiles + "/*.hmm"
        self.chunks = self._getChunks()
        self.seq_assign_to_chunks = self._getSeqAssigned()
        self.project_structure = self._getProjectStructure()
        self.ins_time = {} # LTR seq.id : insertion time
        self.LTRs_to_TEs = {}  # ltr_id = TE_id, chromosome, start, end, isFull, classification

    def _getChunks(self):
        showMessageLevel("Fasta file estimation", level=2)
        return genomeSplitterIndex(self.genome)

    def _getProjectStructure(self):
        """
        this will create all directories needed for the project
        :return:
        """
        showMessageLevel("Project structure generation", level=2)
        project_structure = ProjectStructure(args.out, self.chunks, self.genome)
        print(project_structure)
        return project_structure

    def start_iRAPer(self, chunk, genome_fasta):
        ltr = LTRharvestRun(genome_fasta, skip=self.skip) #results will be _sorted.gff3 file
        ltr.getLTR_from_LTRharvesGff3()
        self.project_structure.addLTRfastaPath(chunk)  # add path to the 3' LTR and 5' LTR
        #
        # classification_TE_path = ltr_di[1] # return path to the 3' LTR fasta generated by LTRdigest
        # self.project_structure.classification_TE_path.append(classification_TE_path)
        # self.project_structure.addLTRfastaPath(chunk, ltr_fasta_path) # add path to the 3' LTR and 5' LTR


    def createGenomeFastas(self):
        """
        it will create chunks genome fasta in each tmp folder
        :return:
        """
        showMessageLevel("Genome fasta files are creating", level=2)
        chunk_in_process = 0
        genome_fasta = self.project_structure.genomes_tmp[chunk_in_process]
        tmp_fasta = open(genome_fasta, "w")
        files_created = []
        files_created.append(genome_fasta)
        cnt = 1
        for seq in SeqIO.parse(self.genome, "fasta"):
            chunk_current = self.seq_assign_to_chunks[seq.id]  # chunk for this sequence
            if chunk_current != chunk_in_process:
                tmp_fasta.close()
                chunk_in_process = chunk_current
                genome_fasta = self.project_structure.genomes_tmp[chunk_in_process]
                files_created.append(genome_fasta)
                tmp_fasta = open(genome_fasta, "w")
                SeqIO.write(seq, tmp_fasta, "fasta")
                cnt += 1
            else:
                SeqIO.write(seq, tmp_fasta, "fasta")

        showMessageLevel("Number of tmp genome fasta files created {}".format(cnt), level=2)
        return files_created

    def _getSeqAssigned(self):
        """
        assign chunks to indovodual sequences
        :return: dictionary seq.id:chunk
        """
        seq_assigned  = {}
        for i,chunks in enumerate(self.chunks):
            for seq_ids in chunks:
                seq_assigned[seq_ids] = i
        return seq_assigned


    def mergeLTRfasta(self):
        """
        :return: two merged fasta files for 3'LTR and 5'LTR sequences
        """
        ## 3 LTR
        os.system('cat {0} > {1}'.format(' '.join([self.project_structure.ltr_3[i] for i in self.project_structure.ltr_3]),
                  self.project_structure.merged_3))
        ## 5 LTR
        os.system(
            'cat {0} > {1}'.format(' '.join([self.project_structure.ltr_5[i] for i in self.project_structure.ltr_5]),
                                   self.project_structure.merged_5))

    def clustering(self):
        os.system('cdhit -i {0} -o {1} -s 0.4 -aL 0.5 -d 150 -T 0'.format(self.project_structure.merged_3,
                                                                          self.project_structure.cd_hit_fasta))
        ## parse the results
        cl = Clustering_LTRs.CdHit_clustering(self.project_structure.cd_hit_results,
                                         self.project_structure.parsed_cd_hit_out)

        showInfoMessage("Maximum sequences ({0}) in cluster {1}".format(len(cl.getMaximumCluster()), cl.getMaximumCluster().id))


    def runBLAST(self):
        os.system("makeblastdb -in {0} -out {0} -dbtype nucl".format(self.project_structure.genome_blastDB))
        #3'-LTR BLAST
        os.system("blastn -query {0} "
                  "-db {1} -outfmt 5 "
                  "-out {2} -evalue 0.000001 "
                  "-window_size 22 -num_threads 20".format(self.project_structure.selection_sequence3_per_cluster,
                                                           self.project_structure.genome_blastDB,
                                                           self.project_structure.BLAST_3LTR_xml))
        #5'-LTR BLAST
        os.system("blastn -query {0} "
                  "-db {1} -outfmt 5 "
                  "-out {2} -evalue 0.000001 "
                  "-window_size 22 -num_threads 20".format(self.project_structure.selection_sequence5_per_cluster,
                                                           self.project_structure.genome_blastDB,
                                                           self.project_structure.BLAST_5LTR_xml))

    def findLTRsInGenome(self):
        checkLTR_bygBLAST(
            self.project_structure.BLAST_3LTR_xml,
            ltr=3)
        checkLTR_bygBLAST(
            self.project_structure.BLAST_3LTR_xml,
            ltr=5)

    def findOverlap(self, chromosome, start, end, TE_classification):
        for TEs in TE_classification:
            TEs = TE_classification[TEs]
            if chromosome == chromosome:
                if not (start > TEs[3] and end > TEs[3]) and not (start < TEs[2] and end < TEs[2]):
                    return TEs
        return None


    def getClassification(self):
        classification_dictionary = {} # TE_id: TE_id, chromosome, start, end, isFull, classification
        with open(self.project_structure.merged_classification_TE_path) as classification:
            for lines in classification:
                sp = lines.rstrip().split("\t")
                classification_dictionary[sp[0]] = sp[0],sp[1],int(sp[2]),int(sp[3]),sp[4],sp[6]  # TE_id, chromosome, start, end, isFull, classification
        return classification_dictionary

    def getTEline(self, te_class_item):
        """
        input: list from self.Te_classification dictionary
                chromosome, start, end, length, classification
        :return: line for writing in final file
        """

        chromosome, start, end = te_class_item[0].split('_')
        return "\t".join([str(i) for i in [chromosome, start, end, te_class_item[3], te_class_item[4]]])

    def getBest(self, ltr5_primers, ltr3_primers):
        """
        :return:
        """
        showMessageLevel("BEST PRIMER PAIR SELECTION for {}".format(ltr5_primers[0][0]),level=1)
        tm_frequency_sel = [] ## [[ [primer1_3LTR_array],[primer2_3LTR_array]....],[[primer1_5LTR_array],[..],[..] ..] ]
        for array in [ltr5_primers,ltr3_primers]:
            #[self.TE_id,
            # primer,
            #    start + 1,
            #    start + self.window,
            #    primer,
            #    fr,
            # round(GC(Seq(primer)), 1),
            #                     Tm,
            #    str(self.ltr) + "LTR"]
            ## Tm filtration
            tm = [i for i in array if i[-2] > 58 and i[-2] < 62]
            if not tm:
                showWarning("Tm value is not appropriate for this TE {}. NO best primers will be catched for this TE".format(array[0]))
                return False

            ## primer occurency frequency filtration
            fr = [i for i in tm if int(i[-4].split('/')[0]) / int(i[-4].split('/')[0]) > 0.7]
            if not fr:
                showWarning("Primer occurency frequency . NO best primers will be catched for this TE")
                return False
            tm_frequency_sel.append(fr)

        # find not_overlapping_pairs
        sel_pairs = []
        for primers5 in tm_frequency_sel[0]:
            for primer3 in tm_frequency_sel[1]:
                if int(primers5[3]) < int(primer3[2]):
                    sel_pairs.append([primers5,primer3])
        if not sel_pairs:
            showWarning("No primers with appropriate order found. NO best primers will be catched for this TE")
            return False
        ## select pairs with maximum distance between the primer
        bes_pair = max(sel_pairs, key=lambda x: abs(int(x[0][3]) - int(x[1][2])))
        return bes_pair

    def __listTostr(self, list_inp):
        return ([str(i) for i in list_inp])

    def run(self):
        ### step 1: estimate fasta file and calculate number of chunks needed

        ### step 2: create projects structure and corresponding folders and subfolders

        ### step 3:  split genome into fasta file for each chunk
        files_created = self.createGenomeFastas()

        ### step 4: iterate across all files and run LTRharvest and LTRdigest
        for chunk, genome in enumerate(files_created):
            showStep("LTR identification in file: " + genome)
            self.start_iRAPer(chunk, genome)

        #os.system('cat {0} > {1}'.format(" ".join(self.project_structure.classification_TE_path), self.project_structure.merged_classification_TE_path))

        ### step 5: merge fasta files for each chunk into 5' LTR and 3' LTR
        showStep("merging of 3' and 5' LTR fasta files from different chunks")
        self.mergeLTRfasta() # results  self.project_structure.merged_3 and self.project_structure.merged_5 fasta files
        showMessageLevel("File {0} and {1} have been created".format(self.project_structure.merged_3,
                                                                     self.project_structure.merged_5),
                         level=1)

        ### step 6: estimate insertion time
        showStep("insertion time estimation")
        self.ins_time = LTR_InsertionTimeCalculator(self.project_structure.merged_3,
                                    self.project_structure.merged_5,
                                    self.project_structure.insertion_time_tab,
                                    self.skip).ins_time
        showMessageLevel("File {} has been created".format(self.project_structure.insertion_time_tab),
                         level=1)



        ### step 7: clustering of 3â€™ LTR sequences by CD-HIT
        showStep("LTR clustering")
        self.clustering()

        ### step 8: select clusters and sequences from them
        showStep("Selecting clusters based on TE age and cluster size")

        seq_ids, cluster_leading_dic, seq_per_cluster = \
            selectClusters_and_LTRs(self.project_structure.parsed_cd_hit_out,
                                self.project_structure.insertion_time_tab,
                                self.project_structure.selection_tab_cluster
                                )


        ### step 9: SELECTION BASED ON TE structure ###
        #### merge TE bodies ###
        showStep('Selecting clusters and sequences based on TE stricture and annotation')
        os.system(
            'cat {0} > {1}'.format(' '.join([self.project_structure.TE_body[i] for i in self.project_structure.TE_body]),
                                   self.project_structure.merged_TE_body))

        ##select only TE bodies that are in selected clusters
        cnt =0
        selected_TEs = {} # TE id : SeqRecord
        with open(self.project_structure.selected_merged_TE_body, "w") as outFile:
            for seq in SeqIO.parse(self.project_structure.merged_TE_body, 'fasta'):
                if seq.id in seq_ids:
                    SeqIO.write(seq, outFile, 'fasta')
                    selected_TEs[seq.id] = seq
                    cnt +=1
        showInfoMessage("{0} TE sequences from selected clusters have been written in a file {1} for LTRdigest run".format(cnt, self.project_structure.selected_merged_TE_body))

        showStep('TE domain identification')
        # return classificiation file fullpath
        LD_TE_body = LTRharvestRun(self.project_structure.selected_merged_TE_body, skip=self.skip)
        classification_TE_tab = LD_TE_body.runLTRdigest(self.trna, self.profiles)
        showInfoMessage("{} table with TE classification information".format(classification_TE_tab))
        #####
        #it will write two fasts files for 3' LTR and 5' LTR
        selectBy_isFUll_classification(classification_TE_tab,
                                       cluster_leading_dic, seq_per_cluster,
                                        self.project_structure.merged_3,
                                       self.project_structure.merged_5,
                                       self.project_structure.selection_sequence3_per_cluster,
                                self.project_structure.selection_sequence5_per_cluster)

        ### step 10: BLAST
        showStep("BLAST for selected 3'LTRs and 5'LTRs is going")
        self.runBLAST()

        ### step 11: Collection of LTR similar sequences from genome
        showStep("Collection of LTR similar sequences from whole genome")

        ltr3_collected_sim_seqs = checkLTR_bygBLAST(
            self.project_structure.BLAST_3LTR_xml,
        ltr=3)
        ltr5_collected_sim_seqs = checkLTR_bygBLAST(
            self.project_structure.BLAST_5LTR_xml,
            ltr=5)

        ### step 12: ClustalO multiple alignment of the collected fastas
        showStep('final step: >>>> iRAP primer design')
        print("\n".join(ltr3_collected_sim_seqs.created_fastas))
        print("////////")
        print("\n".join(ltr5_collected_sim_seqs.created_fastas))
        print("////////")
        cnt_best_pair = 0
        with open(self.project_structure.outTableBEST, "w") as outFinal, \
            open(self.project_structure.TE_fastaBEST, "w") as outFASTA:
            outFinal.write("\t".join(["TE id","Primer",
                                      "Start", "End",
                                      "Expected/Available number of loci aligned",
                                      "GC", "Tm", "LTR",
                                     "TE_chromosome", "TE_start", "TE_end", "TE_length","TE_classification", "TE_insertion_time", "Cluster"
                                      ]) + "\n")
            for i,ltr3_files in enumerate(ltr3_collected_sim_seqs.created_fastas):
                showMessageLevel("Alignment of the LTR sequences and primer design for {0} of {1} sequences".format(i,len(ltr3_collected_sim_seqs.created_fastas)),level=2)
                best_3 = RunAndParseClustal(ltr3_files, self.project_structure.tmp_folder + "/3LTR_{}.tmp_tab".format(i),ltr=3, run_clustal=self.skip != True)
                ltr_5_fasta = ltr3_files.replace("::3::","::5::")
                ltr_5_fasta = ltr_5_fasta.replace("LTR3", "LTR5")
                best_5 = RunAndParseClustal(ltr_5_fasta, self.project_structure.tmp_folder + "/5LTR_{}.tmp_tab".format(i),ltr=5, run_clustal=self.skip != True)
                showMessageLevel('',level=2)

                if best_5.best and best_3.best:
                    best_pair = self.getBest(best_5.best, best_3.best)
                    if best_pair:
                        cnt_best_pair += 1
                        best_5_pr, best_3_pr = best_pair

                        # add information about TE
                        best_5_pr.append(self.getTEline(LD_TE_body.TE_classification_tab[best_5_pr[0]]))

                        # add insertion time information
                        best_5_pr.append(self.ins_time[best_5_pr[0]])

                        # add cluster number
                        best_5_pr.append(seq_ids[best_5_pr[0]])

                        #### for 5' LTR just add blank because it is the same TE
                        best_3_pr.append('\t'.join(['-' for i in range(6) ]))


                        outFinal.write("\t".join(self.__listTostr(best_5_pr)) + "\n")
                        outFinal.write("\t".join(self.__listTostr(best_3_pr)) + "\n")

                        SeqIO.write(selected_TEs[best_3_pr[0]], outFASTA, "fasta")

        showInfoMessage('FINAL SET OF PRIMERS SELECTED CONTAINS {} PRIMER PAIRS. More primer variants can be found in /tmp folder'.format(cnt_best_pair))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Short sample app')

    # Required arguments
    parser.add_argument('genome', help = "Path to the file of genome fasta sequence")
    parser.add_argument('trna', help = "Path to the file with tRNA fasta")
    parser.add_argument('profiles', help = "Path to the folder with .hmm profiles")


    # optional arguments
    parser.add_argument('-o',"--outdir",dest='out',default=".", help = "output directory for iRAPer files")
    parser.add_argument('-skip',"--skip", default=False, action="store_true", help = "skip LTRdigest and LTRharvest steps")


    #paths to the programmes used by iRAPer
    soft_group = parser.add_argument_group('software paths')
    soft_group.add_argument("-blastn", action="store", default="blastn", help = "path to the blasnt. Default: blastn")

    # version
    parser.add_argument("-v", '--version', action='version',
                        version='1.0')

###########################################################
    args = parser.parse_args()
    iRAPer(args).run()

